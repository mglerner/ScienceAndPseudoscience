{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the weather!\n",
    "\n",
    "1. Read Randal Olson's [article](http://fivethirtyeight.com/features/what-12-months-of-record-setting-temperatures-looks-like-across-the-u-s/) on 538.\n",
    "2. Read his blog about [making the plots](http://www.randalolson.com/2015/08/13/the-new-york-times-weather-chart-redux/)\n",
    "\n",
    "Now check out the code below. You're **NOT** expected to understand, read and write Python code for this course! We will be tweaking it a bit to do what you want, though!\n",
    "\n",
    "**Instructor note: everybody runs everything through the scraping right now, so it can scrape while we're talking.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabbing the data\n",
    "\n",
    "First, we need to grab the data from Wunderground. You can find historical data on pages like [this](http://www.wunderground.com/history/airport/KVES/2015/10/14/DailyHistory.html?req_city=Richmond&req_state=IN&reqdb.zip=47374&reqdb.magic=1&reqdb.wmo=99999).\n",
    "\n",
    "Looking through each of those and writing down all of the values would be a *giant* pain. So, we do what's called \"web scraping\" to automate the process. It looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_station(station):\n",
    "    '''\n",
    "    This function scrapes the weather data web pages from wunderground.com\n",
    "    for the station you provide it.\n",
    "    You can look up your city's weather station by performing a search for\n",
    "    it on wunderground.com then clicking on the \"History\" section.\n",
    "    The 4-letter name of the station will appear on that page.\n",
    "    '''\n",
    "\n",
    "    # Scrape between July 1, 2014 and July 1, 2015\n",
    "    # You can change the dates here if you prefer to scrape a different range\n",
    "    current_date = datetime(year=2014, month=7, day=1)\n",
    "    end_date = datetime(year=2015, month=7, day=1)\n",
    "\n",
    "    # Make sure a directory exists for the station web pages\n",
    "    os.mkdir(station)\n",
    "\n",
    "    # Use .format(station, YYYY, M, D)\n",
    "    lookup_URL = 'http://www.wunderground.com/history/airport/{}/{}/{}/{}/DailyHistory.html'\n",
    "\n",
    "    while current_date != end_date:\n",
    "\n",
    "        if current_date.day == 1:\n",
    "            print(current_date)\n",
    "\n",
    "        formatted_lookup_URL = lookup_URL.format(station,\n",
    "                                                 current_date.year,\n",
    "                                                 current_date.month,\n",
    "                                                 current_date.day)\n",
    "        html = urlopen(formatted_lookup_URL).read().decode('utf-8')\n",
    "\n",
    "        out_file_name = '{}/{}-{}-{}.html'.format(station, current_date.year,\n",
    "                                                  current_date.month,\n",
    "                                                  current_date.day)\n",
    "\n",
    "        with open(out_file_name, 'w') as out_file:\n",
    "            out_file.write(html)\n",
    "\n",
    "        current_date += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grabbing Richmond's data\n",
    "\n",
    "We could then grab Richmond's data with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scrape_station('KVES')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing\n",
    "\n",
    "That grabs the raw web pages.\n",
    "\n",
    "We then need to make sense of the above information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_station(station):\n",
    "    '''\n",
    "    This function parses the web pages downloaded from wunderground.com\n",
    "    into a flat CSV file for the station you provide it.\n",
    "\n",
    "    Make sure to run the wunderground scraper first so you have the web\n",
    "    pages downloaded.\n",
    "    '''\n",
    "\n",
    "    # Scrape between July 1, 2014 and July 1, 2015\n",
    "    # You can change the dates here if you prefer to parse a different range\n",
    "    current_date = datetime(year=2014, month=7, day=1)\n",
    "    end_date = datetime(year=2015, month=7, day=1)\n",
    "\n",
    "    with open('{}.csv'.format(station), 'w') as out_file:\n",
    "        out_file.write('date,actual_mean_temp,actual_min_temp,actual_max_temp,'\n",
    "                       'average_min_temp,average_max_temp,'\n",
    "                       'record_min_temp,record_max_temp,'\n",
    "                       'record_min_temp_year,record_max_temp_year,'\n",
    "                       'actual_precipitation,average_precipitation,'\n",
    "                       'record_precipitation\\n')\n",
    "\n",
    "        while current_date != end_date:\n",
    "            try_again = False\n",
    "            with open('{}/{}-{}-{}.html'.format(station,\n",
    "                                                current_date.year,\n",
    "                                                current_date.month,\n",
    "                                                current_date.day)) as in_file:\n",
    "                soup = BeautifulSoup(in_file.read(), 'html.parser')\n",
    "\n",
    "                weather_data = soup.find(id='historyTable').find_all('span', class_='wx-value')\n",
    "                weather_data_units = soup.find(id='historyTable').find_all('td')\n",
    "\n",
    "                try:\n",
    "                    actual_mean_temp = weather_data[0].text\n",
    "                    actual_max_temp = weather_data[2].text\n",
    "                    average_max_temp = weather_data[3].text\n",
    "                    record_max_temp = weather_data[4].text\n",
    "                    actual_min_temp = weather_data[5].text\n",
    "                    average_min_temp = weather_data[6].text\n",
    "                    record_min_temp = weather_data[7].text\n",
    "                    record_max_temp_year = weather_data_units[\n",
    "                        9].text.split('(')[-1].strip(')')\n",
    "                    record_min_temp_year = weather_data_units[\n",
    "                        13].text.split('(')[-1].strip(')')\n",
    "\n",
    "                    actual_precipitation = weather_data[9].text\n",
    "                    if actual_precipitation == 'T':\n",
    "                        actual_precipitation = '0.0'\n",
    "                    average_precipitation = weather_data[10].text\n",
    "                    record_precipitation = weather_data[11].text\n",
    "\n",
    "                    # Verify that the parsed data is valid\n",
    "                    if (record_max_temp_year == '-1' or record_min_temp_year == '-1' or\n",
    "                            int(record_max_temp) < max(int(actual_max_temp), int(average_max_temp)) or\n",
    "                            int(record_min_temp) > min(int(actual_min_temp), int(average_min_temp)) or\n",
    "                            float(actual_precipitation) > float(record_precipitation) or\n",
    "                            float(average_precipitation) > float(record_precipitation)):\n",
    "                        raise Exception\n",
    "\n",
    "                    out_file.write('{}-{}-{},'.format(current_date.year, current_date.month, current_date.day))\n",
    "                    out_file.write(','.join([actual_mean_temp, actual_min_temp, actual_max_temp,\n",
    "                                             average_min_temp, average_max_temp,\n",
    "                                             record_min_temp, record_max_temp,\n",
    "                                             record_min_temp_year, record_max_temp_year,\n",
    "                                             actual_precipitation, average_precipitation,\n",
    "                                             record_precipitation]))\n",
    "                    out_file.write('\\n')\n",
    "                    current_date += timedelta(days=1)\n",
    "                except:\n",
    "                    # If the web page is formatted improperly, signal that the page may need\n",
    "                    # to be downloaded again.\n",
    "                    try_again = True\n",
    "\n",
    "            # If the web page needs to be downloaded again, re-download it from\n",
    "            # wunderground.com\n",
    "\n",
    "            # If the parser gets stuck on a certain date, you may need to investigate\n",
    "            # the page to find out what is going on. Sometimes data is missing, in\n",
    "            # which case the parser will get stuck. You can manually put in the data\n",
    "            # yourself in that case, or just tell the parser to skip this day.\n",
    "            if try_again:\n",
    "                \n",
    "                print('Error with date {}'.format(current_date))\n",
    "                \n",
    "                actual_mean_temp = '0.0'\n",
    "                actual_max_temp = '0.0'\n",
    "                average_max_temp = '0.0'\n",
    "                record_max_temp = '0.0'\n",
    "                actual_min_temp = '0.0'\n",
    "                average_min_temp = '0.0'\n",
    "                record_min_temp = '0.0'\n",
    "                record_max_temp_year = '0.0'\n",
    "                record_min_temp_year = '0.0'\n",
    "\n",
    "                actual_precipitation = '0.0'\n",
    "                average_precipitation = '0.0'\n",
    "                record_precipitation = '0.0'\n",
    "\n",
    "                out_file.write('{}-{}-{},'.format(current_date.year, current_date.month, current_date.day))\n",
    "                out_file.write(','.join([actual_mean_temp, actual_min_temp, actual_max_temp,\n",
    "                                         average_min_temp, average_max_temp,\n",
    "                                         record_min_temp, record_max_temp,\n",
    "                                         record_min_temp_year, record_max_temp_year,\n",
    "                                         actual_precipitation, average_precipitation,\n",
    "                                         record_precipitation]))\n",
    "                out_file.write('\\n')\n",
    "                current_date += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parse_station('KVES')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize!\n",
    "\n",
    "Now let's make some pretty plots!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def visualize_station(station):\n",
    "    weather_data = pd.read_csv(station+'.csv', parse_dates=['date'])\n",
    "    print(weather_data.describe())\n",
    "\n",
    "    # Generate a bunch of histograms of the data to make sure that all of the data\n",
    "    # is in an expected range.\n",
    "\n",
    "    '''\n",
    "    I also use a custom matplotlib style as the basis for these charts, which you\n",
    "    can find here: https://gist.githubusercontent.com/rhiever/d0a7332fe0beebfdc3d5/raw/223d70799b48131d5ce2723cd5784f39d7a3a653/tableau10.mplstyle\n",
    "    '''\n",
    "\n",
    "    with plt.style.context('https://gist.githubusercontent.com/rhiever/d0a7332fe0beebfdc3d5/raw/223d70799b48131d5ce2723cd5784f39d7a3a653/tableau10.mplstyle'):\n",
    "        for column in weather_data.columns:\n",
    "            if column in ['date']:\n",
    "                continue\n",
    "            plt.figure()\n",
    "            plt.hist(weather_data[column].values)\n",
    "            plt.title(column)\n",
    "            plt.savefig('{}.png'.format(column))\n",
    "\n",
    "        # Make sure we're only plotting temperatures for July 2014 - June 2015\n",
    "        weather_data_subset = weather_data[weather_data['date'] >= datetime(year=2014, month=7, day=1)]\n",
    "        weather_data_subset = weather_data_subset[weather_data_subset['date'] < datetime(year=2015, month=6, day=30)].copy()\n",
    "        weather_data_subset['day_order'] = range(len(weather_data_subset))\n",
    "\n",
    "        day_order = weather_data_subset['day_order']\n",
    "        record_max_temps = weather_data_subset['record_max_temp'].values\n",
    "        record_min_temps = weather_data_subset['record_min_temp'].values\n",
    "        average_max_temps = weather_data_subset['average_max_temp'].values\n",
    "        average_min_temps = weather_data_subset['average_min_temp'].values\n",
    "        actual_max_temps = weather_data_subset['actual_max_temp'].values\n",
    "        actual_min_temps = weather_data_subset['actual_min_temp'].values\n",
    "\n",
    "        fig, ax1 = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "        # Create the bars showing all-time record highs and lows\n",
    "        plt.bar(day_order, record_max_temps - record_min_temps, bottom=record_min_temps,\n",
    "                edgecolor='none', color='#C3BBA4', width=1)\n",
    "\n",
    "        # Create the bars showing average highs and lows\n",
    "        plt.bar(day_order, average_max_temps - average_min_temps, bottom=average_min_temps,\n",
    "                edgecolor='none', color='#9A9180', width=1)\n",
    "\n",
    "        # Create the bars showing this year's highs and lows\n",
    "        plt.bar(day_order, actual_max_temps - actual_min_temps, bottom=actual_min_temps,\n",
    "                edgecolor='black', linewidth=0.5, color='#5A3B49', width=1)\n",
    "\n",
    "        new_max_records = weather_data_subset[weather_data_subset.record_max_temp <= weather_data_subset.actual_max_temp]\n",
    "        new_min_records = weather_data_subset[weather_data_subset.record_min_temp >= weather_data_subset.actual_min_temp]\n",
    "\n",
    "        # Create the dots marking record highs and lows for the year\n",
    "        plt.scatter(new_max_records['day_order'].values + 0.5,\n",
    "                    new_max_records['actual_max_temp'].values + 1.25,\n",
    "                    s=15, zorder=10, color='#d62728', alpha=0.75, linewidth=0)\n",
    "\n",
    "        plt.scatter(new_min_records['day_order'].values + 0.5,\n",
    "                    new_min_records['actual_min_temp'].values - 1.25,\n",
    "                    s=15, zorder=10, color='#1f77b4', alpha=0.75, linewidth=0)\n",
    "\n",
    "        plt.ylim(-50, 141)\n",
    "        plt.xlim(-5, 370)\n",
    "\n",
    "        plt.yticks(range(-50, 141, 10), [r'{}$^\\circ$'.format(x)\n",
    "                                         for x in range(-50, 141, 10)], fontsize=10)\n",
    "        plt.ylabel(r'Temperature ($^\\circ$F)', fontsize=12)\n",
    "\n",
    "        month_beginning_df = weather_data_subset[weather_data_subset['date'].apply(lambda x: True if x.day == 1 else False)]\n",
    "        month_beginning_indeces = list(month_beginning_df['day_order'].values)\n",
    "        month_beginning_names = list(month_beginning_df['date'].apply(lambda x: x.strftime(\"%B\")).values)\n",
    "        month_beginning_names[0] += '\\n\\'14'\n",
    "        month_beginning_names[6] += '\\n\\'15'\n",
    "\n",
    "        # Add the last month label manually\n",
    "        month_beginning_indeces += [weather_data_subset['day_order'].values[-1]]\n",
    "        month_beginning_names += ['July']\n",
    "\n",
    "        plt.xticks(month_beginning_indeces,\n",
    "                   month_beginning_names,\n",
    "                   fontsize=10)\n",
    "\n",
    "        ax2 = ax1.twiny()\n",
    "        plt.xticks(month_beginning_indeces,\n",
    "                   month_beginning_names,\n",
    "                   fontsize=10)\n",
    "\n",
    "        plt.xlim(-5, 370)\n",
    "        plt.grid(False)\n",
    "\n",
    "        ax3 = ax1.twinx()\n",
    "        plt.yticks(range(-50, 141, 10), [r'{}$^\\circ$'.format(x)\n",
    "                                         for x in range(-50, 141, 10)], fontsize=10)\n",
    "        plt.ylim(-50, 141)\n",
    "        plt.grid(False)\n",
    "\n",
    "        plt.title(station+'\\'s weather, July 2014 - June 2015\\n\\n', fontsize=20)\n",
    "\n",
    "        plt.savefig(station+'-weather-july14-june15.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_station('KVES')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems!\n",
    "\n",
    "Look for the data from Jan/Feb.\n",
    "\n",
    "Ah. So, my DS students have collected nearby data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_station('KVES-fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
