{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the weather!\n",
    "\n",
    "1. Read Randal Olson's [article](http://fivethirtyeight.com/features/what-12-months-of-record-setting-temperatures-looks-like-across-the-u-s/) on 538.\n",
    "2. Read his blog about [making the plots](http://www.randalolson.com/2015/08/13/the-new-york-times-weather-chart-redux/)\n",
    "\n",
    "Now check out the code below. You're **NOT** expected to understand, read and write Python code for this course! We will be tweaking it a bit to do what you want, though!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabbing the data\n",
    "\n",
    "First, we need to grab the data from Wunderground. You can find historical data on pages like [this](http://www.wunderground.com/history/airport/KVES/2015/10/14/DailyHistory.html?req_city=Richmond&req_state=IN&reqdb.zip=47374&reqdb.magic=1&reqdb.wmo=99999).\n",
    "\n",
    "Looking through each of those and writing down all of the values would be a *giant* pain. So, we do what's called \"web scraping\" to automate the process. It looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_station(station):\n",
    "    '''\n",
    "    This function scrapes the weather data web pages from wunderground.com\n",
    "    for the station you provide it.\n",
    "    You can look up your city's weather station by performing a search for\n",
    "    it on wunderground.com then clicking on the \"History\" section.\n",
    "    The 4-letter name of the station will appear on that page.\n",
    "    '''\n",
    "\n",
    "    # Scrape between July 1, 2014 and July 1, 2015\n",
    "    # You can change the dates here if you prefer to scrape a different range\n",
    "    current_date = datetime(year=2014, month=7, day=1)\n",
    "    end_date = datetime(year=2015, month=7, day=1)\n",
    "\n",
    "    # Make sure a directory exists for the station web pages\n",
    "    os.mkdir(station)\n",
    "\n",
    "    # Use .format(station, YYYY, M, D)\n",
    "    lookup_URL = 'http://www.wunderground.com/history/airport/{}/{}/{}/{}/DailyHistory.html'\n",
    "\n",
    "    while current_date != end_date:\n",
    "\n",
    "        if current_date.day == 1:\n",
    "            print(current_date)\n",
    "\n",
    "        formatted_lookup_URL = lookup_URL.format(station,\n",
    "                                                 current_date.year,\n",
    "                                                 current_date.month,\n",
    "                                                 current_date.day)\n",
    "        html = urlopen(formatted_lookup_URL).read().decode('utf-8')\n",
    "\n",
    "        out_file_name = '{}/{}-{}-{}.html'.format(station, current_date.year,\n",
    "                                                  current_date.month,\n",
    "                                                  current_date.day)\n",
    "\n",
    "        with open(out_file_name, 'w') as out_file:\n",
    "            out_file.write(html)\n",
    "\n",
    "        current_date += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grabbing Richmond's data\n",
    "\n",
    "We could then grab Richmond's data with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scrape_station(station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing\n",
    "\n",
    "That grabs the raw web pages.\n",
    "\n",
    "We then need to make sense of the above information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_station(station):\n",
    "    '''\n",
    "    This function parses the web pages downloaded from wunderground.com\n",
    "    into a flat CSV file for the station you provide it.\n",
    "\n",
    "    Make sure to run the wunderground scraper first so you have the web\n",
    "    pages downloaded.\n",
    "    '''\n",
    "\n",
    "    # Scrape between July 1, 2014 and July 1, 2015\n",
    "    # You can change the dates here if you prefer to parse a different range\n",
    "    current_date = datetime(year=2014, month=7, day=1)\n",
    "    end_date = datetime(year=2015, month=7, day=1)\n",
    "\n",
    "    with open('{}.csv'.format(station), 'w') as out_file:\n",
    "        out_file.write('date,actual_mean_temp,actual_min_temp,actual_max_temp,'\n",
    "                       'average_min_temp,average_max_temp,'\n",
    "                       'record_min_temp,record_max_temp,'\n",
    "                       'record_min_temp_year,record_max_temp_year,'\n",
    "                       'actual_precipitation,average_precipitation,'\n",
    "                       'record_precipitation\\n')\n",
    "\n",
    "        while current_date != end_date:\n",
    "            try_again = False\n",
    "            with open('{}/{}-{}-{}.html'.format(station,\n",
    "                                                current_date.year,\n",
    "                                                current_date.month,\n",
    "                                                current_date.day)) as in_file:\n",
    "                soup = BeautifulSoup(in_file.read(), 'html.parser')\n",
    "\n",
    "                weather_data = soup.find(id='historyTable').find_all('span', class_='wx-value')\n",
    "                weather_data_units = soup.find(id='historyTable').find_all('td')\n",
    "\n",
    "                try:\n",
    "                    actual_mean_temp = weather_data[0].text\n",
    "                    actual_max_temp = weather_data[2].text\n",
    "                    average_max_temp = weather_data[3].text\n",
    "                    record_max_temp = weather_data[4].text\n",
    "                    actual_min_temp = weather_data[5].text\n",
    "                    average_min_temp = weather_data[6].text\n",
    "                    record_min_temp = weather_data[7].text\n",
    "                    record_max_temp_year = weather_data_units[\n",
    "                        9].text.split('(')[-1].strip(')')\n",
    "                    record_min_temp_year = weather_data_units[\n",
    "                        13].text.split('(')[-1].strip(')')\n",
    "\n",
    "                    actual_precipitation = weather_data[9].text\n",
    "                    if actual_precipitation == 'T':\n",
    "                        actual_precipitation = '0.0'\n",
    "                    average_precipitation = weather_data[10].text\n",
    "                    record_precipitation = weather_data[11].text\n",
    "\n",
    "                    # Verify that the parsed data is valid\n",
    "                    if (record_max_temp_year == '-1' or record_min_temp_year == '-1' or\n",
    "                            int(record_max_temp) < max(int(actual_max_temp), int(average_max_temp)) or\n",
    "                            int(record_min_temp) > min(int(actual_min_temp), int(average_min_temp)) or\n",
    "                            float(actual_precipitation) > float(record_precipitation) or\n",
    "                            float(average_precipitation) > float(record_precipitation)):\n",
    "                        raise Exception\n",
    "\n",
    "                    out_file.write('{}-{}-{},'.format(current_date.year, current_date.month, current_date.day))\n",
    "                    out_file.write(','.join([actual_mean_temp, actual_min_temp, actual_max_temp,\n",
    "                                             average_min_temp, average_max_temp,\n",
    "                                             record_min_temp, record_max_temp,\n",
    "                                             record_min_temp_year, record_max_temp_year,\n",
    "                                             actual_precipitation, average_precipitation,\n",
    "                                             record_precipitation]))\n",
    "                    out_file.write('\\n')\n",
    "                    current_date += timedelta(days=1)\n",
    "                except:\n",
    "                    # If the web page is formatted improperly, signal that the page may need\n",
    "                    # to be downloaded again.\n",
    "                    try_again = True\n",
    "\n",
    "            # If the web page needs to be downloaded again, re-download it from\n",
    "            # wunderground.com\n",
    "\n",
    "            # If the parser gets stuck on a certain date, you may need to investigate\n",
    "            # the page to find out what is going on. Sometimes data is missing, in\n",
    "            # which case the parser will get stuck. You can manually put in the data\n",
    "            # yourself in that case, or just tell the parser to skip this day.\n",
    "            if try_again:\n",
    "                \n",
    "                print('Error with date {}'.format(current_date))\n",
    "                \n",
    "                actual_mean_temp = '0.0'\n",
    "                actual_max_temp = '0.0'\n",
    "                average_max_temp = '0.0'\n",
    "                record_max_temp = '0.0'\n",
    "                actual_min_temp = '0.0'\n",
    "                average_min_temp = '0.0'\n",
    "                record_min_temp = '0.0'\n",
    "                record_max_temp_year = '0.0'\n",
    "                record_min_temp_year = '0.0'\n",
    "\n",
    "                actual_precipitation = '0.0'\n",
    "                average_precipitation = '0.0'\n",
    "                record_precipitation = '0.0'\n",
    "\n",
    "                out_file.write('{}-{}-{},'.format(current_date.year, current_date.month, current_date.day))\n",
    "                out_file.write(','.join([actual_mean_temp, actual_min_temp, actual_max_temp,\n",
    "                                         average_min_temp, average_max_temp,\n",
    "                                         record_min_temp, record_max_temp,\n",
    "                                         record_min_temp_year, record_max_temp_year,\n",
    "                                         actual_precipitation, average_precipitation,\n",
    "                                         record_precipitation]))\n",
    "                out_file.write('\\n')\n",
    "                current_date += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but don't do it! Why? Look for the data from Jan/Feb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah. So, my DS students have collected nearby data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
